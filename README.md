# ğŸ“„ PDF QA Chatbot â€“ Athina AI Assignment

A **Streamlit-based PDF Question-Answering chatbot** that allows you to upload PDF documents, process their content into embeddings, and then ask natural language questions. The chatbot retrieves relevant context and generates detailed answers, while also evaluating the responses using **BLEU**, **ROUGE**, and **BERTScore** metrics.

---

## ğŸš€ Features
- **Multiple PDF Upload** â€“ Upload one or more PDF documents at once.
- **Text Extraction** â€“ Extracts text from all PDF pages.
- **Text Chunking** â€“ Splits large documents into smaller chunks for efficient retrieval.
- **Vector Store** â€“ Uses **FAISS** for fast similarity search over embedded text.
- **Conversational QA** â€“ Retrieves relevant context and answers questions using **Google Gemini**.
- **Evaluation Metrics** â€“ Automatically computes:
  - BLEU Score
  - ROUGE Score
  - BERTScore (Precision, Recall, F1)
- **JSON Logging** â€“ Saves query, context, and generated response to a JSON file.

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ app.py                # Main Streamlit application
â”œâ”€â”€ output_data.json      # Saved Q&A and evaluation results
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation
```

---

## ğŸ› ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/pdf-qa-chatbot.git
cd pdf-qa-chatbot
```

### 2ï¸âƒ£ Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate     # On Windows
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Environment Variables
Create a `.env` file in the root directory and add your **Google API key**:

```
GOOGLE_API_KEY=your_google_api_key_here
```

You can get a Google API key from the [Google AI Studio](https://aistudio.google.com/).

---

## â–¶ï¸ Usage
Run the Streamlit app:
```bash
streamlit run app.py
```

1. Upload one or more PDF files from the **sidebar**.
2. Click **"Submit & Process"** to extract and store embeddings.
3. Enter your question in the text input box.
4. View:
   - Generated answer
   - BLEU, ROUGE, and BERTScore metrics
   - Logged output in `output_data.json`

---

## ğŸ“Š Example Output

**Console log:**
```
Context: [Top relevant document chunk...]
Generated Response: [Model's answer...]
BLEU Score: 56.43
ROUGE Scores: {'rouge1': ..., 'rouge2': ..., 'rougeL': ...}
BERT Scores - Precision: tensor([0.93]) Recall: tensor([0.91]) F1: tensor([0.92])
```

**Streamlit UI:**
- Generated response displayed
- BLEU score displayed
- ROUGE-1 score displayed
- Precision, Recall, F1 displayed

---

## ğŸ“¦ Dependencies
- `streamlit`
- `PyPDF2`
- `langchain`
- `langchain_google_genai`
- `google-generativeai`
- `faiss-cpu`
- `sacrebleu`
- `rouge-score`
- `bert-score`
- `python-dotenv`

---

## ğŸ“œ License
This project is licensed under the MIT License.

---

## ğŸ¤ Acknowledgements
- [LangChain](https://www.langchain.com/) for text processing and chain management.
- [Google Generative AI](https://aistudio.google.com/) for embeddings and chat model.
- [FAISS](https://faiss.ai/) for vector similarity search.
- [Streamlit](https://streamlit.io/) for the interactive UI.
